{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Analysis\n",
    "\n",
    "For this analysis I used the pandas, pylab, and numpy libraries in Python. I also used statsmodels to fit a logistic regression with 'admit' as the response variable and gre, gpa and prestige as predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/ranaquadri/Documents/recipe/recipe_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['title','recipe_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "pct = (df.isnull().sum() / df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, pct], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.loc[missing_data['Total'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with missing rating and/or nutritional info\n",
    "df = df[pd.notnull(df['rating'])]\n",
    "df = df[pd.notnull(df['nut_cals'])]\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop 4 observations where rating <2\n",
    "df[df.rating < 2].count()\n",
    "\n",
    "df = df.drop(df[df.rating < 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop observations with > 5K reviews\n",
    "df[df.num_reviews > 5000].count()\n",
    "\n",
    "df = df.drop(df[df.num_reviews>5000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set to null 56 observations where ratio sugar_flour >5. \n",
    "df[df.ratio_sugar_flour > 5].count()\n",
    "df.loc[df.ratio_sugar_flour > 5, 'ratio_sugar_flour'] = np.nan\n",
    "df.loc[df.ratio_fat_flour > 5, 'ratio_fat_flour'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set data types of variables\n",
    "df['pos_adj']=df['pos_adj'].astype('bool');\n",
    "df['health_adj']=df['health_adj'].astype('bool');\n",
    "df['nut_sod']=df['nut_sod'].astype('int');\n",
    "df['nut_choles']=df['nut_choles'].astype('int');\n",
    "df['num_reviews']=df['num_reviews'].astype('int');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create bins for rating in order to use neural network\n",
    "df['rat_cat']=pd.cut(df['rating'], bins=4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster=df_cluster[df_cluster.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recipe_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data Visualization\n",
    "\n",
    "# Scatterplot of ratio sugar/flour vs rating\n",
    "df.plot.scatter(x='rating', y='ratio_sugar_flour')\n",
    "\n",
    "# Scatterplot of ratio sugar/flour vs rating\n",
    "df.plot.scatter(x='rating', y='ratio_fat_flour')\n",
    "\n",
    "# Scatterplot of ratio sugar/flour vs rating\n",
    "df.plot.scatter(x='rating', y='num_reviews')\n",
    "\n",
    "# Scatterplot of ratio sugar/flour vs rating\n",
    "df.plot.scatter(x='rating', y='nut_cals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of each variable \n",
    "df[\"ratio_sugar_flour\"].plot(kind=\"density\")\n",
    "df[\"ratio_fat_flour\"].plot(kind=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nut_cals\"].plot(kind=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster=df[['num_reviews','nut_cals','nut_carb','nut_choles','nut_fat','nut_prot','nut_sod','social_rank',\n",
    "             'sugar','fat','dry','recipe_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cluster['rec_type'] = df['recipe_type'].map({'other':0, 'cookies': 1, 'cake':2, 'scones':3, 'pie':4, 'brownies':5, 'snickerdoodles':1,'muffins':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster.drop(['recipe_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=pd.crosstab(df.rat_cat, df.pos_adj).apply(lambda r: r/r.sum(), axis=1)\n",
    "stacked = ct.stack().reset_index().rename(columns={0:'value'})\n",
    " # plot grouped bar chart\n",
    "sn.barplot(x=stacked.rat_cat, y=stacked.value, hue=stacked.pos_adj)\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Percent\")\n",
    "plt.title(\"Positive Adjective vs Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ct=pd.crosstab(df.rat_cat, df.health_adj).apply(lambda r: r/r.sum(), axis=1)\n",
    "stacked = ct.stack().reset_index().rename(columns={0:'value'})\n",
    " # plot grouped bar chart\n",
    "sn.barplot(x=stacked.rat_cat, y=stacked.value, hue=stacked.health_adj)\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Percent\")\n",
    "plt.title(\"Health Adjective vs Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df['rating'].describe()\n",
    "print(\"Skewness: {0:0.3f}\".format(df['rating'].skew()))\n",
    "print(\"Kurtosis: {0:0.3f}\".format(df['rating'].kurt()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlation map\n",
    "f, ax = plt.subplots(figsize=(9,9))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_cluster1 = StandardScaler().fit_transform(df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#KMeans\n",
    "sns.set_context('poster')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.5, 's' : 80, 'linewidths':0}\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "km_cluster_model = KMeans(n_clusters=6, random_state=1)\n",
    "km_cluster_model.fit(df_cluster)\n",
    "labels = km_cluster_model.predict(df_cluster1)\n",
    "\n",
    "\n",
    "palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(df_cluster1.T[0], df_cluster1.T[1], c=colors, **plot_kwds)\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)\n",
    "plt.title('Clusters found by {}'.format(str(KMeans.__name__)), fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[\"cluster\"] = labels\n",
    "df_cluster = pd.concat([df_cluster, pd.get_dummies(df_cluster['cluster'], prefix=\"cluster\")], axis=1)\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "lm = smf.ols(formula='rating ~ pos_adj+health_adj+nut_prot+num_reviews+ratio_sugar_flour+recipe_type', data=df).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_keep=['num_reviews','nut_cals','nut_carb','nut_choles','nut_fat','nut_prot','nut_sod','social_rank',\n",
    "             'sugar','fat','dry', 'pos_adj','health_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df['rat_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[cols_to_keep], df['rat_cat'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden = n_input\n",
    "n_output = 4\n",
    "\n",
    "model.add(Dense(n_hidden, input_dim=n_input, activation='relu'))\n",
    "model.add(Dense(n_output, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=400, batch_size=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_non_category = [ np.argmax(t) for t in y_test ]\n",
    "y_predict_non_category = [ np.argmax(t) for t in y_pred ]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score,recall_score\n",
    "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)\n",
    "\n",
    "print conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test_non_category, y_predict_non_category,average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "recall_score(y_test_non_category, y_predict_non_category,average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "       \n",
    "df_cm = pd.DataFrame(conf_mat, range(4),\n",
    "                  range(4))\n",
    "sn.set(font_scale=1.1)\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 13},cmap=\"YlGnBu\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix for Neural Network\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
